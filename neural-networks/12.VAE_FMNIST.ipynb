{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jngadiub/ML_course_Pavia_23/blob/main/neural-networks/12.VAE_FMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate FashionMNIST data with VAE with Keras\n",
        "\n",
        "In this tutorial, we will train a generator of images using a VAE model in Keras. For illustration we will use the FashionMNIST dataset."
      ],
      "metadata": {
        "id": "3rZzyVOXXjtf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPnZQ6IQoarT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras.backend as K\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Lambda, Reshape, Conv2D, Conv2DTranspose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-KGsDfkrgg3"
      },
      "source": [
        "## Load and Process the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbCf8Zjtrj48"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "print(X_train.shape, '\\t', y_train.shape)\n",
        "print(X_test.shape, '\\t', y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toLMOHBGXJ-k"
      },
      "source": [
        "The pixel values in the data lie between 0 and 255. So, we need to normalise them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8TxYbPEr_TP"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHSEY0okXJ-m"
      },
      "source": [
        "Now, we use the .`reshape()` fucntion to reshape our data in the format expected by TensorFlow layer i.e., (no of samples, width, height, no of channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t6EctfcsIXf"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape((-1,28,28,1))\n",
        "X_test = X_test.reshape((-1,28,28,1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-xa2i8Jsg9H"
      },
      "source": [
        "## Visualization of Samples\n",
        "We plot a few random observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6J3BW6Dsj2J"
      },
      "outputs": [],
      "source": [
        "plt.figure(1)\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[20][:,:,0])\n",
        "\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[300][:,:,0])\n",
        "\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[4000][:,:,0])\n",
        "\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[5000][:,:,0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PebaeBW-s7XN"
      },
      "source": [
        "## Model Architecture\n",
        "We now design our VAE model; which involves of an encoder, the latent space and a decoder. Model implementation wise, the latent space can be considered to be a part of the encoder\n",
        "\n",
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWlPmFD_s-aV"
      },
      "outputs": [],
      "source": [
        "enc_input = Input(shape=(28,28,1), name='encoder input')\n",
        "x = Conv2D(128, 5, padding='same', activation='relu')(enc_input)\n",
        "x = Conv2D(64, 3, padding='same', strides=2, activation='relu')(x)\n",
        "x = Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "x = Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "\n",
        "enc_shape = K.int_shape(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9CBTssFuBN1"
      },
      "outputs": [],
      "source": [
        "x = Flatten()(x)\n",
        "x = Dense(32)(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEDmPOo6uKV6"
      },
      "source": [
        "#### Latent Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPv4BNEguMQL"
      },
      "outputs": [],
      "source": [
        "latent_dim = 2 #2D space\n",
        "\n",
        "z_mean = Dense(latent_dim, name='Z-mean')(x)\n",
        "z_logvar = Dense(latent_dim, name='Z-logvariance')(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrADefA7vgqx"
      },
      "source": [
        "We need to define a function that takes in the mean and log variance parameters and return a random sample from the resulting distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSEatnQzu3eK"
      },
      "outputs": [],
      "source": [
        "def sampling(args):\n",
        "  mean, logvar = args\n",
        "  eps = K.random_normal([latent_dim])\n",
        "  rnd_sam = mean + K.exp(logvar/2) * eps\n",
        "  return rnd_sam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I5zlGlkXJ-5"
      },
      "source": [
        "By using a Lambda layer, we can thus define our latent space as shown below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Wyuggl-vvni"
      },
      "outputs": [],
      "source": [
        "z = Lambda(sampling, output_shape=latent_dim, name='latent-space')([z_mean, z_logvar])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gw-DT3Gxsnq"
      },
      "outputs": [],
      "source": [
        "encoder = keras.Model(enc_input, z, name='encoder')\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Te984czx_66"
      },
      "source": [
        "### Decoder\n",
        "Here, we need to take the randomly sampled 2D latent space vector and convert it back to the original format of the image i.e., 28x28 with a single channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOGz4qMQyBkF"
      },
      "outputs": [],
      "source": [
        "dec_input = Input(shape=(latent_dim,), name='decoder-input')\n",
        "\n",
        "true_shape = enc_shape[1:]\n",
        "\n",
        "y = Dense(np.prod(true_shape))(dec_input)\n",
        "y = Reshape(target_shape=true_shape)(y)\n",
        "y = Conv2DTranspose(64, 3, padding='same', activation='relu')(y)\n",
        "y = Conv2DTranspose(64, 3, padding='same', activation='relu')(y)\n",
        "y = Conv2DTranspose(64, 3, strides=2, padding='same', activation='relu')(y)\n",
        "y = Conv2DTranspose(128, 5, padding='same', activation='relu')(y)\n",
        "y = Conv2DTranspose(1, 5, padding='same', activation='relu')(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZYrb8im1IE5"
      },
      "outputs": [],
      "source": [
        "decoder = keras.Model(dec_input, y, name='decoder')\n",
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVcnm05g1urU"
      },
      "source": [
        "### Connecting all components,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeFTgI5V10bB"
      },
      "outputs": [],
      "source": [
        "enc_output = encoder(enc_input)\n",
        "dec_output = decoder(enc_output)\n",
        "\n",
        "\n",
        "vae = keras.Model(enc_input, dec_output, name='VAE')\n",
        "vae.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px760Myi2xjO"
      },
      "source": [
        "## Training\n",
        "First, we need to define a custom loss function which trains our model based to improve an error defined as the sum of reconstruction loss and KL-Divergence loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CC1B70Qt2zWK"
      },
      "outputs": [],
      "source": [
        "def loss_func(z_mean, z_logvar):\n",
        "\n",
        "    def vae_reconstruction_loss(y_true, y_predict):\n",
        "        reconstruction_loss_factor = 100\n",
        "        reconstruction_loss = K.mean(K.square(y_true-y_predict), axis=[1, 2, 3])\n",
        "        return reconstruction_loss_factor * reconstruction_loss\n",
        "\n",
        "    def vae_kl_loss(z_mean, z_logvar):\n",
        "        kl_loss = -0.5 * K.sum(1.0 + z_logvar - K.square(z_mean) - K.exp(z_logvar), axis=1)\n",
        "        return kl_loss\n",
        "\n",
        "    def vae_kl_loss_metric(y_true, y_predict):\n",
        "        kl_loss = -0.5 * K.sum(1.0 + z_logvar - K.square(z_mean) - K.exp(z_logvar), axis=1)\n",
        "        return kl_loss\n",
        "\n",
        "    def vae_loss(y_true, y_predict):\n",
        "        reconstruction_loss = vae_reconstruction_loss(y_true, y_predict)\n",
        "        kl_loss = vae_kl_loss(y_true, y_predict)\n",
        "\n",
        "        loss = reconstruction_loss + kl_loss\n",
        "        return loss\n",
        "\n",
        "    return vae_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc4FAiroXJ--"
      },
      "source": [
        "We can now compile and train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kx2Qwquz3lDN"
      },
      "outputs": [],
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "vae.compile(optimizer=opt, loss=loss_func(z_mean, z_logvar))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7i4b5AL35LT"
      },
      "outputs": [],
      "source": [
        "history = vae.fit(X_train, X_train, epochs=20, batch_size=32, validation_data=(X_test, X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyHF8JEhXJ_A"
      },
      "source": [
        "Here, we performed naive hyperparameter tuning and achieved the above results. Whether the above loss is satisfactory or not depends on how well the model can reconstruct a given sample. This can only be gauged by visualising a few test observations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7jo2xW3HI0W"
      },
      "source": [
        "## Visualization of Test samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fB28ZFlIHN3h"
      },
      "outputs": [],
      "source": [
        "index = int(input())\n",
        "\n",
        "y_pred = vae.predict(X_test[:10,:])\n",
        "\n",
        "plt.figure(1)\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_test[index].reshape(28,28))\n",
        "\n",
        "plt.subplot(222)\n",
        "plt.imshow(y_pred[index].reshape(28,28))\n",
        "\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_test[index*5].reshape(28,28))\n",
        "\n",
        "plt.subplot(224)\n",
        "plt.imshow(y_pred[index*5].reshape(28,28))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwqjMhAjXJ_E"
      },
      "source": [
        "As seen above, the model is successful in reconstructing the general shape of the clothing item but finer details like text or patters are lost. For our case, this is satisfactory"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}